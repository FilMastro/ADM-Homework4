{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b13301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20714d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6797b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 5 # TODO: to be tuned!\n",
    "THRESHOLD = 0 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29192c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d042f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tracks,N_TRACKS,DURATION):\n",
    "    len_peaks = []\n",
    "    all_peaks = []\n",
    "    \n",
    "    for idx, audio in enumerate(tracks):\n",
    "        if idx >= N_TRACKS:\n",
    "            break\n",
    "        track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "        all_peaks.append(peaks.tolist())\n",
    "        len_peaks.append(max(peaks))\n",
    "        \n",
    "    return max(len_peaks), all_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4062c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaksToDataframe(DURATION):\n",
    "    tracks = data_folder.glob(\"*/*/*.wav\")\n",
    "    MAX, peaks = max_length(tracks,N_TRACKS, DURATION)\n",
    "    mat = np.zeros((N_TRACKS, MAX), dtype=int)\n",
    "    \n",
    "    for idx in range(N_TRACKS):\n",
    "        for j in range(MAX):\n",
    "            if(j in peaks[idx]):\n",
    "                mat[idx][j] = 1    \n",
    "    return(pd.DataFrame(mat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afa252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Current Time = 11:16:14\n",
      "20\n",
      "Current Time = 11:19:39\n",
      "30\n",
      "Current Time = 11:26:24\n",
      "40\n",
      "Current Time = 11:36:33\n",
      "50\n",
      "Current Time = 11:49:30\n",
      "60\n",
      "Current Time = 12:05:40\n",
      "70\n",
      "Current Time = 12:24:54\n",
      "80\n",
      "Current Time = 12:47:13\n",
      "90\n",
      "Current Time = 13:13:08\n",
      "100\n",
      "Current Time = 13:42:03\n",
      "110\n",
      "Current Time = 14:13:37\n",
      "120\n",
      "Current Time = 14:48:25\n",
      "130\n",
      "Current Time = 15:26:09\n",
      "140\n",
      "Current Time = 16:07:14\n",
      "150\n",
      "Current Time = 16:51:09\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for i in range(10,160,10):\n",
    "    print(i)\n",
    "    now = datetime.now()\n",
    "\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    print(\"Current Time =\", current_time)\n",
    "    \n",
    "    df = peaksToDataframe(i)\n",
    "    df.to_csv(str(i)+\"-duration.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
