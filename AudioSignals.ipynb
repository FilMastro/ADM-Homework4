{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ad47ad0-476b-418a-81e4-894570f7cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np      \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.io.wavfile \n",
    "import subprocess\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import random\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path, PurePath   \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7d781-ece8-4ad9-959e-f498d8a76666",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23224edb-25aa-4415-a86f-19ef3c233b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mp3_to_wav(audio:str) -> str:  \n",
    "    \"\"\"Convert an input MP3 audio track into a WAV file.\n",
    "\n",
    "    Args:\n",
    "        audio (str): An input audio track.\n",
    "\n",
    "    Returns:\n",
    "        [str]: WAV filename.\n",
    "    \"\"\"\n",
    "    if audio[-3:] == \"mp3\":\n",
    "        wav_audio = audio[:-3] + \"wav\"\n",
    "        if not Path(wav_audio).exists():\n",
    "                subprocess.check_output(f\"ffmpeg -i {audio} {wav_audio}\", shell=True)\n",
    "        return wav_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "def plot_spectrogram_and_picks(track:np.ndarray, sr:int, peaks:np.ndarray, onset_env:np.ndarray) -> None:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        track (np.ndarray): A track.\n",
    "        sr (int): Aampling rate.\n",
    "        peaks (np.ndarray): Indices of peaks in the track.\n",
    "        onset_env (np.ndarray): Vector containing the onset strength envelope.\n",
    "    \"\"\"\n",
    "    times = librosa.frames_to_time(np.arange(len(onset_env)),\n",
    "                            sr=sr, hop_length=HOP_SIZE)\n",
    "\n",
    "    plt.figure()\n",
    "    ax = plt.subplot(2, 1, 2)\n",
    "    D = librosa.stft(track)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max),\n",
    "                            y_axis='log', x_axis='time')\n",
    "    plt.subplot(2, 1, 1, sharex=ax)\n",
    "    plt.plot(times, onset_env, alpha=0.8, label='Onset strength')\n",
    "    plt.vlines(times[peaks], 0,\n",
    "            onset_env.max(), color='r', alpha=0.8,\n",
    "            label='Selected peaks')\n",
    "    plt.legend(frameon=True, framealpha=0.8)\n",
    "    plt.axis('tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def load_audio_picks(audio, duration, hop_size):\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        audio (string, int, pathlib.Path or file-like object): [description]\n",
    "        duration (int): [description]\n",
    "        hop_size (int): \n",
    "\n",
    "    Returns:\n",
    "        tuple: Returns the audio time series (track) and sampling rate (sr), a vector containing the onset strength envelope\n",
    "        (onset_env), and the indices of peaks in track (peaks).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        track, sr = librosa.load(audio, duration=duration)\n",
    "        onset_env = librosa.onset.onset_strength(track, sr=sr, hop_length=hop_size)\n",
    "        peaks = librosa.util.peak_pick(onset_env, 10, 10, 10, 10, 0.5, 0.5)\n",
    "    except Error as e:\n",
    "        print('An error occurred processing ', str(audio))\n",
    "        print(e)\n",
    "\n",
    "    return track, sr, onset_env, peaks\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1faac1-c07e-45dc-9dd0-7582d95dfdc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1e0e19-443a-4557-a810-fc76146aab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRACKS = 1413\n",
    "HOP_SIZE = 512\n",
    "DURATION = 30 # TODO: to be tuned!\n",
    "THRESHOLD = 0 # TODO: to be tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b951e3bc-06a6-4b4d-beb9-196ff4734422",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"D:/ADM/data/mp3s-32k/\")\n",
    "mp3_tracks = data_folder.glob(\"*/*/*.mp3\")\n",
    "tracks = data_folder.glob(\"*/*/*.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30631e-43fc-4802-9bb5-13f8e34eae35",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384a028f-bee3-4052-b478-26e702b4d03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a1625a84c449158c9f2bc685f9c0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for track in tqdm(mp3_tracks, total=N_TRACKS):\n",
    "    convert_mp3_to_wav(str(track))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e76bf-dce3-4bcb-a240-baed8d3f76a1",
   "metadata": {},
   "source": [
    "## Audio Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93b92fe5-6e29-49fe-b802-37bdc999da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, audio in enumerate(tracks):\n",
    "    if idx >= 4:\n",
    "        break\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    plot_spectrogram_and_picks(track, sr, peaks, onset_env)\n",
    "    seed = [1,132,48,962,95,88]\n",
    "    print(minhash(peaks,DURATION,seed[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc5b01fb-95f0-4b2a-9deb-66a5d6fe9f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a5099b314f489a917a294afbc9b2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating dictionary\n",
    "thirty_sec = OrderedDict()\n",
    "for idx, audio in tqdm(enumerate(tracks),total = N_TRACKS):\n",
    "\n",
    "    track, sr, onset_env, peaks = load_audio_picks(audio, DURATION, HOP_SIZE)\n",
    "    thirty_sec[idx] = peaks\n",
    "with open('thirty_sec.pkl','wb') as f:\n",
    "    pickle.dump(thirty_sec,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de6418d8-652d-4e89-a656-d6811383451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dict\n",
    "with open('thirty_sec.pkl','rb') as f:\n",
    "    thirty_sec = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086a1598-d77d-4dd3-8dae-451e46c23459",
   "metadata": {},
   "source": [
    "## Minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bece8e9-f253-4263-818e-049267d9b876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash(peaks,DURATION,seed):\n",
    "    random.seed(seed)\n",
    "    coeff=random.sample([i for i in range(3000)],len(peaks))\n",
    "    val=sum(np.multiply(coeff,peaks))\n",
    "    bin_=val%1410\n",
    "    return bin_\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d855df9-772f-44c9-9e0e-27a81a1f8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [21,123,45,87,656]\n",
    "# for every hash function\n",
    "for i in range(len(seeds)):\n",
    "    bins=defaultdict(list)\n",
    "    # for every song\n",
    "    for k, v in thirty_sec.items():\n",
    "        bins[minhash(v,DURATION,seeds[i])].append(k)\n",
    "    with open('bins_h({}).pkl'.format(i+1),'wb') as f:\n",
    "        pickle.dump(bins,f)\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c26553bf-fdfb-4f14-a135-2e20c4a103e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bins_h(1).pkl','rb') as f:\n",
    "    bins_1 = pickle.load(f)\n",
    "with open('bins_h(2).pkl','rb') as f:\n",
    "    bins_2 = pickle.load(f)\n",
    "with open('bins_h(3).pkl','rb') as f:\n",
    "    bins_3 = pickle.load(f)\n",
    "with open('bins_h(4).pkl','rb') as f:\n",
    "    bins_4 = pickle.load(f)\n",
    "with open('bins_h(5).pkl','rb') as f:\n",
    "    bins_5 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d49ff588-e354-4790-b397-55d8464f2445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash della query: [357, 342, 1293, 358, 1171]\n",
      "canzoni in ogni bin relativo all hash [1367] [548, 1108, 1367] [717, 1244, 1367] [1149, 1367] [1367]\n"
     ]
    }
   ],
   "source": [
    "# now that we have the bins, we analyze queries\n",
    "q_bin=[]\n",
    "for i in range(len(seeds)):\n",
    "    track, sr, onset_env, peaks = load_audio_picks('D:/ADM/data/queries/track3.wav', DURATION, HOP_SIZE)\n",
    "    value = minhash(peaks,DURATION,seeds[i])\n",
    "    q_bin.append(value)\n",
    "print(\"hash della query:\",q_bin)\n",
    "print('canzoni in ogni bin relativo all hash',bins_1[357],bins_2[342],bins_3[1293],bins_4[358],bins_5[1171])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Laboratorio",
   "language": "python",
   "name": "laboratorio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
